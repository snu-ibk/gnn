{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrxu2Lrfy7fnRwdqZ+Q9TE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snu-ibk/gnn/blob/main/FRAUDRE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FraudDetection/FRAUDRE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwUiDUZetD-7",
        "outputId": "d7a5ed95-d52b-4ff7-f88d-14536c8ec4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'FRAUDRE' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpUEMga4setr",
        "outputId": "9a111ef6-c19d-48aa-daf1-65baf8257f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/ibk/GNN 공부\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DH55BWWswPZ",
        "outputId": "9134e713-870b-49df-bcfb-ef81a66b5eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ibk/GNN 공부\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE')"
      ],
      "metadata": {
        "id": "JE9X3qGftL3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q data/Amazon.zip -d data\n",
        "# !unzip -q data/YelpChi.zip -d data"
      ],
      "metadata": {
        "id": "PxD4wt2dvAL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run train.py"
      ],
      "metadata": {
        "id": "wA9Jc3bAuZyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e20fa03a-b8be-413f-d91e-a73e9853af7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run on amazon\n",
            "load start\n",
            "add self loop\n",
            "creat adj_list\n",
            "for loop start\n",
            "for loop end\n",
            "sparse_to_adjlist def end\n",
            "homo load done\n",
            "add self loop\n",
            "creat adj_list\n",
            "for loop start\n",
            "for loop end\n",
            "sparse_to_adjlist def end\n",
            "add self loop\n",
            "creat adj_list\n",
            "for loop start\n",
            "for loop end\n",
            "sparse_to_adjlist def end\n",
            "add self loop\n",
            "creat adj_list\n",
            "for loop start\n",
            "for loop end\n",
            "sparse_to_adjlist def end\n",
            "initialize model input\n",
            "build model\n",
            "first convolution layer\n",
            "second convolution layer\n",
            "Epoch: 0, batch: 0\n",
            "Epoch: 0, batch: 1\n",
            "Epoch: 0, batch: 2\n",
            "Epoch: 0, batch: 3\n",
            "Epoch: 0, batch: 4\n",
            "Epoch: 0, batch: 5\n",
            "Epoch: 0, batch: 6\n",
            "Epoch: 0, batch: 7\n",
            "Epoch: 0, batch: 8\n",
            "Epoch: 0, loss: 0.1179360433458548, time: 4.197875499725342s\n",
            "GNN auc: 0.8887\n",
            "GNN precision: 0.9462\n",
            "GNN a_precision: 0.7657\n",
            "GNN Recall: 0.7935\n",
            "GNN f1: 0.8504\n",
            "Epoch: 1, batch: 0\n",
            "Epoch: 1, batch: 1\n",
            "Epoch: 1, batch: 2\n",
            "Epoch: 1, batch: 3\n",
            "Epoch: 1, batch: 4\n",
            "Epoch: 1, batch: 5\n",
            "Epoch: 1, batch: 6\n",
            "Epoch: 1, batch: 7\n",
            "Epoch: 1, batch: 8\n",
            "Epoch: 1, loss: 0.03745905813659077, time: 8.15287470817566s\n",
            "Epoch: 2, batch: 0\n",
            "Epoch: 2, batch: 1\n",
            "Epoch: 2, batch: 2\n",
            "Epoch: 2, batch: 3\n",
            "Epoch: 2, batch: 4\n",
            "Epoch: 2, batch: 5\n",
            "Epoch: 2, batch: 6\n",
            "Epoch: 2, batch: 7\n",
            "Epoch: 2, batch: 8\n",
            "Epoch: 2, loss: 0.00403048872525686, time: 3.399592638015747s\n",
            "Epoch: 3, batch: 0\n",
            "Epoch: 3, batch: 1\n",
            "Epoch: 3, batch: 2\n",
            "Epoch: 3, batch: 3\n",
            "Epoch: 3, batch: 4\n",
            "Epoch: 3, batch: 5\n",
            "Epoch: 3, batch: 6\n",
            "Epoch: 3, batch: 7\n",
            "Epoch: 3, batch: 8\n",
            "Epoch: 3, loss: 0.0502891876271593, time: 4.360006809234619s\n",
            "Epoch: 4, batch: 0\n",
            "Epoch: 4, batch: 1\n",
            "Epoch: 4, batch: 2\n",
            "Epoch: 4, batch: 3\n",
            "Epoch: 4, batch: 4\n",
            "Epoch: 4, batch: 5\n",
            "Epoch: 4, batch: 6\n",
            "Epoch: 4, batch: 7\n",
            "Epoch: 4, batch: 8\n",
            "Epoch: 4, loss: 0.015162862501903114, time: 3.9489870071411133s\n",
            "Epoch: 5, batch: 0\n",
            "Epoch: 5, batch: 1\n",
            "Epoch: 5, batch: 2\n",
            "Epoch: 5, batch: 3\n",
            "Epoch: 5, batch: 4\n",
            "Epoch: 5, batch: 5\n",
            "Epoch: 5, batch: 6\n",
            "Epoch: 5, batch: 7\n",
            "Epoch: 5, batch: 8\n",
            "Epoch: 5, loss: 0.016270091826204057, time: 3.5942699909210205s\n",
            "Epoch: 6, batch: 0\n",
            "Epoch: 6, batch: 1\n",
            "Epoch: 6, batch: 2\n",
            "Epoch: 6, batch: 3\n",
            "Epoch: 6, batch: 4\n",
            "Epoch: 6, batch: 5\n",
            "Epoch: 6, batch: 6\n",
            "Epoch: 6, batch: 7\n",
            "Epoch: 6, batch: 8\n",
            "Epoch: 6, loss: 0.004805683882577688, time: 4.6891114711761475s\n",
            "Epoch: 7, batch: 0\n",
            "Epoch: 7, batch: 1\n",
            "Epoch: 7, batch: 2\n",
            "Epoch: 7, batch: 3\n",
            "Epoch: 7, batch: 4\n",
            "Epoch: 7, batch: 5\n",
            "Epoch: 7, batch: 6\n",
            "Epoch: 7, batch: 7\n",
            "Epoch: 7, batch: 8\n",
            "Epoch: 7, loss: 0.022622052374850703, time: 3.3916823863983154s\n",
            "Epoch: 8, batch: 0\n",
            "Epoch: 8, batch: 1\n",
            "Epoch: 8, batch: 2\n",
            "Epoch: 8, batch: 3\n",
            "Epoch: 8, batch: 4\n",
            "Epoch: 8, batch: 5\n",
            "Epoch: 8, batch: 6\n",
            "Epoch: 8, batch: 7\n",
            "Epoch: 8, batch: 8\n",
            "Epoch: 8, loss: 0.011789887942544831, time: 4.051122665405273s\n",
            "Epoch: 9, batch: 0\n",
            "Epoch: 9, batch: 1\n",
            "Epoch: 9, batch: 2\n",
            "Epoch: 9, batch: 3\n",
            "Epoch: 9, batch: 4\n",
            "Epoch: 9, batch: 5\n",
            "Epoch: 9, batch: 6\n",
            "Epoch: 9, batch: 7\n",
            "Epoch: 9, batch: 8\n",
            "Epoch: 9, loss: 0.0010795684436123133, time: 3.866793632507324s\n",
            "Epoch: 10, batch: 0\n",
            "Epoch: 10, batch: 1\n",
            "Epoch: 10, batch: 2\n",
            "Epoch: 10, batch: 3\n",
            "Epoch: 10, batch: 4\n",
            "Epoch: 10, batch: 5\n",
            "Epoch: 10, batch: 6\n",
            "Epoch: 10, batch: 7\n",
            "Epoch: 10, batch: 8\n",
            "Epoch: 10, loss: 0.023858160909942132, time: 3.5563178062438965s\n",
            "GNN auc: 0.9293\n",
            "GNN precision: 0.8299\n",
            "GNN a_precision: 0.8362\n",
            "GNN Recall: 0.8865\n",
            "GNN f1: 0.8552\n",
            "Epoch: 11, batch: 0\n",
            "Epoch: 11, batch: 1\n",
            "Epoch: 11, batch: 2\n",
            "Epoch: 11, batch: 3\n",
            "Epoch: 11, batch: 4\n",
            "Epoch: 11, batch: 5\n",
            "Epoch: 11, batch: 6\n",
            "Epoch: 11, batch: 7\n",
            "Epoch: 11, batch: 8\n",
            "Epoch: 11, loss: 0.007369769459397608, time: 3.4945404529571533s\n",
            "Epoch: 12, batch: 0\n",
            "Epoch: 12, batch: 1\n",
            "Epoch: 12, batch: 2\n",
            "Epoch: 12, batch: 3\n",
            "Epoch: 12, batch: 4\n",
            "Epoch: 12, batch: 5\n",
            "Epoch: 12, batch: 6\n",
            "Epoch: 12, batch: 7\n",
            "Epoch: 12, batch: 8\n",
            "Epoch: 12, loss: 0.04074465908150096, time: 4.406022548675537s\n",
            "Epoch: 13, batch: 0\n",
            "Epoch: 13, batch: 1\n",
            "Epoch: 13, batch: 2\n",
            "Epoch: 13, batch: 3\n",
            "Epoch: 13, batch: 4\n",
            "Epoch: 13, batch: 5\n",
            "Epoch: 13, batch: 6\n",
            "Epoch: 13, batch: 7\n",
            "Epoch: 13, batch: 8\n",
            "Epoch: 13, loss: 0.0299741582944379, time: 3.603269577026367s\n",
            "Epoch: 14, batch: 0\n",
            "Epoch: 14, batch: 1\n",
            "Epoch: 14, batch: 2\n",
            "Epoch: 14, batch: 3\n",
            "Epoch: 14, batch: 4\n",
            "Epoch: 14, batch: 5\n",
            "Epoch: 14, batch: 6\n",
            "Epoch: 14, batch: 7\n",
            "Epoch: 14, batch: 8\n",
            "Epoch: 14, loss: 0.04749379657798458, time: 4.21938681602478s\n",
            "Epoch: 15, batch: 0\n",
            "Epoch: 15, batch: 1\n",
            "Epoch: 15, batch: 2\n",
            "Epoch: 15, batch: 3\n",
            "Epoch: 15, batch: 4\n",
            "Epoch: 15, batch: 5\n",
            "Epoch: 15, batch: 6\n",
            "Epoch: 15, batch: 7\n",
            "Epoch: 15, batch: 8\n",
            "Epoch: 15, loss: 0.03692728245825364, time: 4.113390684127808s\n",
            "Epoch: 16, batch: 0\n",
            "Epoch: 16, batch: 1\n",
            "Epoch: 16, batch: 2\n",
            "Epoch: 16, batch: 3\n",
            "Epoch: 16, batch: 4\n",
            "Epoch: 16, batch: 5\n",
            "Epoch: 16, batch: 6\n",
            "Epoch: 16, batch: 7\n",
            "Epoch: 16, batch: 8\n",
            "Epoch: 16, loss: 0.021516917182213935, time: 3.5508015155792236s\n",
            "Epoch: 17, batch: 0\n",
            "Epoch: 17, batch: 1\n",
            "Epoch: 17, batch: 2\n",
            "Epoch: 17, batch: 3\n",
            "Epoch: 17, batch: 4\n",
            "Epoch: 17, batch: 5\n",
            "Epoch: 17, batch: 6\n",
            "Epoch: 17, batch: 7\n",
            "Epoch: 17, batch: 8\n",
            "Epoch: 17, loss: 0.01549962622052508, time: 4.84187912940979s\n",
            "Epoch: 18, batch: 0\n",
            "Epoch: 18, batch: 1\n",
            "Epoch: 18, batch: 2\n",
            "Epoch: 18, batch: 3\n",
            "Epoch: 18, batch: 4\n",
            "Epoch: 18, batch: 5\n",
            "Epoch: 18, batch: 6\n",
            "Epoch: 18, batch: 7\n",
            "Epoch: 18, batch: 8\n",
            "Epoch: 18, loss: 0.04530173832430491, time: 3.7518527507781982s\n",
            "Epoch: 19, batch: 0\n",
            "Epoch: 19, batch: 1\n",
            "Epoch: 19, batch: 2\n",
            "Epoch: 19, batch: 3\n",
            "Epoch: 19, batch: 4\n",
            "Epoch: 19, batch: 5\n",
            "Epoch: 19, batch: 6\n",
            "Epoch: 19, batch: 7\n",
            "Epoch: 19, batch: 8\n",
            "Epoch: 19, loss: 0.010379026050268053, time: 4.0840840339660645s\n",
            "Epoch: 20, batch: 0\n",
            "Epoch: 20, batch: 1\n",
            "Epoch: 20, batch: 2\n",
            "Epoch: 20, batch: 3\n",
            "Epoch: 20, batch: 4\n",
            "Epoch: 20, batch: 5\n",
            "Epoch: 20, batch: 6\n",
            "Epoch: 20, batch: 7\n",
            "Epoch: 20, batch: 8\n",
            "Epoch: 20, loss: 0.032621033953800956, time: 3.847992420196533s\n",
            "GNN auc: 0.9259\n",
            "GNN precision: 0.7971\n",
            "GNN a_precision: 0.8341\n",
            "GNN Recall: 0.8804\n",
            "GNN f1: 0.8316\n",
            "Epoch: 21, batch: 0\n",
            "Epoch: 21, batch: 1\n",
            "Epoch: 21, batch: 2\n",
            "Epoch: 21, batch: 3\n",
            "Epoch: 21, batch: 4\n",
            "Epoch: 21, batch: 5\n",
            "Epoch: 21, batch: 6\n",
            "Epoch: 21, batch: 7\n",
            "Epoch: 21, batch: 8\n",
            "Epoch: 21, loss: 0.03783760563326709, time: 4.209038972854614s\n",
            "Epoch: 22, batch: 0\n",
            "Epoch: 22, batch: 1\n",
            "Epoch: 22, batch: 2\n",
            "Epoch: 22, batch: 3\n",
            "Epoch: 22, batch: 4\n",
            "Epoch: 22, batch: 5\n",
            "Epoch: 22, batch: 6\n",
            "Epoch: 22, batch: 7\n",
            "Epoch: 22, batch: 8\n",
            "Epoch: 22, loss: 0.03343418198222267, time: 3.4807353019714355s\n",
            "Epoch: 23, batch: 0\n",
            "Epoch: 23, batch: 1\n",
            "Epoch: 23, batch: 2\n",
            "Epoch: 23, batch: 3\n",
            "Epoch: 23, batch: 4\n",
            "Epoch: 23, batch: 5\n",
            "Epoch: 23, batch: 6\n",
            "Epoch: 23, batch: 7\n",
            "Epoch: 23, batch: 8\n",
            "Epoch: 23, loss: 0.08150147925242694, time: 4.513220548629761s\n",
            "Epoch: 24, batch: 0\n",
            "Epoch: 24, batch: 1\n",
            "Epoch: 24, batch: 2\n",
            "Epoch: 24, batch: 3\n",
            "Epoch: 24, batch: 4\n",
            "Epoch: 24, batch: 5\n",
            "Epoch: 24, batch: 6\n",
            "Epoch: 24, batch: 7\n",
            "Epoch: 24, batch: 8\n",
            "Epoch: 24, loss: 0.033541232859583395, time: 3.5107686519622803s\n",
            "Epoch: 25, batch: 0\n",
            "Epoch: 25, batch: 1\n",
            "Epoch: 25, batch: 2\n",
            "Epoch: 25, batch: 3\n",
            "Epoch: 25, batch: 4\n",
            "Epoch: 25, batch: 5\n",
            "Epoch: 25, batch: 6\n",
            "Epoch: 25, batch: 7\n",
            "Epoch: 25, batch: 8\n",
            "Epoch: 25, loss: 0.036504015555499716, time: 3.6690080165863037s\n",
            "Epoch: 26, batch: 0\n",
            "Epoch: 26, batch: 1\n",
            "Epoch: 26, batch: 2\n",
            "Epoch: 26, batch: 3\n",
            "Epoch: 26, batch: 4\n",
            "Epoch: 26, batch: 5\n",
            "Epoch: 26, batch: 6\n",
            "Epoch: 26, batch: 7\n",
            "Epoch: 26, batch: 8\n",
            "Epoch: 26, loss: 0.008139296415743786, time: 4.4848952293396s\n",
            "Epoch: 27, batch: 0\n",
            "Epoch: 27, batch: 1\n",
            "Epoch: 27, batch: 2\n",
            "Epoch: 27, batch: 3\n",
            "Epoch: 27, batch: 4\n",
            "Epoch: 27, batch: 5\n",
            "Epoch: 27, batch: 6\n",
            "Epoch: 27, batch: 7\n",
            "Epoch: 27, batch: 8\n",
            "Epoch: 27, loss: 0.009406670706974605, time: 3.3820183277130127s\n",
            "Epoch: 28, batch: 0\n",
            "Epoch: 28, batch: 1\n",
            "Epoch: 28, batch: 2\n",
            "Epoch: 28, batch: 3\n",
            "Epoch: 28, batch: 4\n",
            "Epoch: 28, batch: 5\n",
            "Epoch: 28, batch: 6\n",
            "Epoch: 28, batch: 7\n",
            "Epoch: 28, batch: 8\n",
            "Epoch: 28, loss: 0.008829789750270914, time: 4.303206205368042s\n",
            "Epoch: 29, batch: 0\n",
            "Epoch: 29, batch: 1\n",
            "Epoch: 29, batch: 2\n",
            "Epoch: 29, batch: 3\n",
            "Epoch: 29, batch: 4\n",
            "Epoch: 29, batch: 5\n",
            "Epoch: 29, batch: 6\n",
            "Epoch: 29, batch: 7\n",
            "Epoch: 29, batch: 8\n",
            "Epoch: 29, loss: 0.04852219983552039, time: 3.9134390354156494s\n",
            "Epoch: 30, batch: 0\n",
            "Epoch: 30, batch: 1\n",
            "Epoch: 30, batch: 2\n",
            "Epoch: 30, batch: 3\n",
            "Epoch: 30, batch: 4\n",
            "Epoch: 30, batch: 5\n",
            "Epoch: 30, batch: 6\n",
            "Epoch: 30, batch: 7\n",
            "Epoch: 30, batch: 8\n",
            "Epoch: 30, loss: 0.01873255303247166, time: 3.6884400844573975s\n",
            "GNN auc: 0.9335\n",
            "GNN precision: 0.8764\n",
            "GNN a_precision: 0.8394\n",
            "GNN Recall: 0.8882\n",
            "GNN f1: 0.8822\n",
            "Epoch: 31, batch: 0\n",
            "Epoch: 31, batch: 1\n",
            "Epoch: 31, batch: 2\n",
            "Epoch: 31, batch: 3\n",
            "Epoch: 31, batch: 4\n",
            "Epoch: 31, batch: 5\n",
            "Epoch: 31, batch: 6\n",
            "Epoch: 31, batch: 7\n",
            "Epoch: 31, batch: 8\n",
            "Epoch: 31, loss: 0.01960780699208471, time: 3.5496344566345215s\n",
            "Epoch: 32, batch: 0\n",
            "Epoch: 32, batch: 1\n",
            "Epoch: 32, batch: 2\n",
            "Epoch: 32, batch: 3\n",
            "Epoch: 32, batch: 4\n",
            "Epoch: 32, batch: 5\n",
            "Epoch: 32, batch: 6\n",
            "Epoch: 32, batch: 7\n",
            "Epoch: 32, batch: 8\n",
            "Epoch: 32, loss: 0.024853854699108356, time: 4.553499937057495s\n",
            "Epoch: 33, batch: 0\n",
            "Epoch: 33, batch: 1\n",
            "Epoch: 33, batch: 2\n",
            "Epoch: 33, batch: 3\n",
            "Epoch: 33, batch: 4\n",
            "Epoch: 33, batch: 5\n",
            "Epoch: 33, batch: 6\n",
            "Epoch: 33, batch: 7\n",
            "Epoch: 33, batch: 8\n",
            "Epoch: 33, loss: 0.005441974267167947, time: 3.5787198543548584s\n",
            "Epoch: 34, batch: 0\n",
            "Epoch: 34, batch: 1\n",
            "Epoch: 34, batch: 2\n",
            "Epoch: 34, batch: 3\n",
            "Epoch: 34, batch: 4\n",
            "Epoch: 34, batch: 5\n",
            "Epoch: 34, batch: 6\n",
            "Epoch: 34, batch: 7\n",
            "Epoch: 34, batch: 8\n",
            "Epoch: 34, loss: 0.05130146982633787, time: 4.478127956390381s\n",
            "Epoch: 35, batch: 0\n",
            "Epoch: 35, batch: 1\n",
            "Epoch: 35, batch: 2\n",
            "Epoch: 35, batch: 3\n",
            "Epoch: 35, batch: 4\n",
            "Epoch: 35, batch: 5\n",
            "Epoch: 35, batch: 6\n",
            "Epoch: 35, batch: 7\n",
            "Epoch: 35, batch: 8\n",
            "Epoch: 35, loss: 0.018752303106136525, time: 3.60510516166687s\n",
            "Epoch: 36, batch: 0\n",
            "Epoch: 36, batch: 1\n",
            "Epoch: 36, batch: 2\n",
            "Epoch: 36, batch: 3\n",
            "Epoch: 36, batch: 4\n",
            "Epoch: 36, batch: 5\n",
            "Epoch: 36, batch: 6\n",
            "Epoch: 36, batch: 7\n",
            "Epoch: 36, batch: 8\n",
            "Epoch: 36, loss: 0.04560178138049708, time: 3.5831172466278076s\n",
            "Epoch: 37, batch: 0\n",
            "Epoch: 37, batch: 1\n",
            "Epoch: 37, batch: 2\n",
            "Epoch: 37, batch: 3\n",
            "Epoch: 37, batch: 4\n",
            "Epoch: 37, batch: 5\n",
            "Epoch: 37, batch: 6\n",
            "Epoch: 37, batch: 7\n",
            "Epoch: 37, batch: 8\n",
            "Epoch: 37, loss: 0.010786774698109965, time: 4.565977573394775s\n",
            "Epoch: 38, batch: 0\n",
            "Epoch: 38, batch: 1\n",
            "Epoch: 38, batch: 2\n",
            "Epoch: 38, batch: 3\n",
            "Epoch: 38, batch: 4\n",
            "Epoch: 38, batch: 5\n",
            "Epoch: 38, batch: 6\n",
            "Epoch: 38, batch: 7\n",
            "Epoch: 38, batch: 8\n",
            "Epoch: 38, loss: 0.02315687636625262, time: 3.5899734497070312s\n",
            "Epoch: 39, batch: 0\n",
            "Epoch: 39, batch: 1\n",
            "Epoch: 39, batch: 2\n",
            "Epoch: 39, batch: 3\n",
            "Epoch: 39, batch: 4\n",
            "Epoch: 39, batch: 5\n",
            "Epoch: 39, batch: 6\n",
            "Epoch: 39, batch: 7\n",
            "Epoch: 39, batch: 8\n",
            "Epoch: 39, loss: 0.032299223030104726, time: 4.006019115447998s\n",
            "Epoch: 40, batch: 0\n",
            "Epoch: 40, batch: 1\n",
            "Epoch: 40, batch: 2\n",
            "Epoch: 40, batch: 3\n",
            "Epoch: 40, batch: 4\n",
            "Epoch: 40, batch: 5\n",
            "Epoch: 40, batch: 6\n",
            "Epoch: 40, batch: 7\n",
            "Epoch: 40, batch: 8\n",
            "Epoch: 40, loss: 0.0029475549797392826, time: 3.864499092102051s\n",
            "GNN auc: 0.9319\n",
            "GNN precision: 0.9054\n",
            "GNN a_precision: 0.8389\n",
            "GNN Recall: 0.8881\n",
            "GNN f1: 0.8965\n",
            "Epoch: 41, batch: 0\n",
            "Epoch: 41, batch: 1\n",
            "Epoch: 41, batch: 2\n",
            "Epoch: 41, batch: 3\n",
            "Epoch: 41, batch: 4\n",
            "Epoch: 41, batch: 5\n",
            "Epoch: 41, batch: 6\n",
            "Epoch: 41, batch: 7\n",
            "Epoch: 41, batch: 8\n",
            "Epoch: 41, loss: 0.014568615348896093, time: 4.016809463500977s\n",
            "Epoch: 42, batch: 0\n",
            "Epoch: 42, batch: 1\n",
            "Epoch: 42, batch: 2\n",
            "Epoch: 42, batch: 3\n",
            "Epoch: 42, batch: 4\n",
            "Epoch: 42, batch: 5\n",
            "Epoch: 42, batch: 6\n",
            "Epoch: 42, batch: 7\n",
            "Epoch: 42, batch: 8\n",
            "Epoch: 42, loss: 0.01555360789146288, time: 3.5624680519104004s\n",
            "Epoch: 43, batch: 0\n",
            "Epoch: 43, batch: 1\n",
            "Epoch: 43, batch: 2\n",
            "Epoch: 43, batch: 3\n",
            "Epoch: 43, batch: 4\n",
            "Epoch: 43, batch: 5\n",
            "Epoch: 43, batch: 6\n",
            "Epoch: 43, batch: 7\n",
            "Epoch: 43, batch: 8\n",
            "Epoch: 43, loss: 0.024819019939265947, time: 4.526899576187134s\n",
            "Epoch: 44, batch: 0\n",
            "Epoch: 44, batch: 1\n",
            "Epoch: 44, batch: 2\n",
            "Epoch: 44, batch: 3\n",
            "Epoch: 44, batch: 4\n",
            "Epoch: 44, batch: 5\n",
            "Epoch: 44, batch: 6\n",
            "Epoch: 44, batch: 7\n",
            "Epoch: 44, batch: 8\n",
            "Epoch: 44, loss: 0.0216835702752721, time: 3.556926965713501s\n",
            "Epoch: 45, batch: 0\n",
            "Epoch: 45, batch: 1\n",
            "Epoch: 45, batch: 2\n",
            "Epoch: 45, batch: 3\n",
            "Epoch: 45, batch: 4\n",
            "Epoch: 45, batch: 5\n",
            "Epoch: 45, batch: 6\n",
            "Epoch: 45, batch: 7\n",
            "Epoch: 45, batch: 8\n",
            "Epoch: 45, loss: 0.03047052761553449, time: 3.545006513595581s\n",
            "Epoch: 46, batch: 0\n",
            "Epoch: 46, batch: 1\n",
            "Epoch: 46, batch: 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    164\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/model.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, nodes, labels, train_flag)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m#the classification module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mscores_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mscores_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_model\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nodes, train_flag)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mscores_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nodes, train_flag)\u001b[0m\n\u001b[1;32m    136\u001b[0m                         \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                         \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/train.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m#def __init__(self, features, embed_dim, adj_lists, intraggs, cuda = False):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0magg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInterAgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0magg1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mintra2_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintra2_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintra2_3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mgnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;31m# gnn_model in one convolution layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nodes, train_flag)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mr1_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintra_agg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr1_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_nodes_new_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mr2_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintra_agg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_nodes_new_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0mr3_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintra_agg3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr3_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_nodes_new_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embedding, nodes, neighbor_lists, unique_nodes_new_index, self_feats)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0membed_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0m_feats_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                         \u001b[0m_feats_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_feats_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Amazon Dataset"
      ],
      "metadata": {
        "id": "jGkdFrP9Htz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import io\n",
        "\n",
        "# 데이터 파일 불러오기\n",
        "mat_file = io.loadmat('data/Amazon_old.mat')\n",
        "print(mat_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZAH8d0GuiuC",
        "outputId": "67183b07-bbaf-440e-d090-ac1f6fd720c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Wed Aug 19 20:20:49 2020', '__version__': '1.0', '__globals__': [], 'homo': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n",
            "\twith 8796784 stored elements in Compressed Sparse Column format>, 'net_upu': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n",
            "\twith 351216 stored elements in Compressed Sparse Column format>, 'net_usu': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n",
            "\twith 7132958 stored elements in Compressed Sparse Column format>, 'net_uvu': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n",
            "\twith 2073474 stored elements in Compressed Sparse Column format>, 'features': <11944x25 sparse matrix of type '<class 'numpy.float64'>'\n",
            "\twith 174488 stored elements in Compressed Sparse Column format>, 'label': array([[0., 0., 0., ..., 0., 0., 0.]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in mat_file:\n",
        "  print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPA02tG8v1CK",
        "outputId": "4de9afb7-9dd6-42d1-cb2a-42c22640c957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__header__\n",
            "__version__\n",
            "__globals__\n",
            "homo\n",
            "net_upu\n",
            "net_usu\n",
            "net_uvu\n",
            "features\n",
            "label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "homo = mat_file['homo']\n",
        "net_upu = mat_file['net_upu']\n",
        "net_usu = mat_file['net_usu']\n",
        "net_uvu = mat_file['net_uvu']\n",
        "features = mat_file['features']\n",
        "label = mat_file['label']"
      ],
      "metadata": {
        "id": "-9DaU9kxwknS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTNEHOvmHqX6",
        "outputId": "3b16699f-99ac-4277-f598-0d522ed17332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgTe7UdqH5lH",
        "outputId": "de872841-1c32-4c67-a1fa-38855b1d6836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(features)"
      ],
      "metadata": {
        "id": "HaKflCK5IAZL",
        "outputId": "08d64109-214f-43ca-a52a-d01c2a9e057e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csc.csc_matrix"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>scipy.sparse._csc.csc_matrix</b><br/>def __init__(arg1, shape=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/scipy/sparse/_csc.py</a>Compressed Sparse Column matrix\n",
              "\n",
              "This can be instantiated in several ways:\n",
              "\n",
              "    csc_array(D)\n",
              "        with a dense matrix or rank-2 ndarray D\n",
              "\n",
              "    csc_array(S)\n",
              "        with another sparse matrix S (equivalent to S.tocsc())\n",
              "\n",
              "    csc_array((M, N), [dtype])\n",
              "        to construct an empty matrix with shape (M, N)\n",
              "        dtype is optional, defaulting to dtype=&#x27;d&#x27;.\n",
              "\n",
              "    csc_array((data, (row_ind, col_ind)), [shape=(M, N)])\n",
              "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
              "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
              "\n",
              "    csc_array((data, indices, indptr), [shape=(M, N)])\n",
              "        is the standard CSC representation where the row indices for\n",
              "        column i are stored in ``indices[indptr[i]:indptr[i+1]]``\n",
              "        and their corresponding values are stored in\n",
              "        ``data[indptr[i]:indptr[i+1]]``.  If the shape parameter is\n",
              "        not supplied, the matrix dimensions are inferred from\n",
              "        the index arrays.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "dtype : dtype\n",
              "    Data type of the matrix\n",
              "shape : 2-tuple\n",
              "    Shape of the matrix\n",
              "ndim : int\n",
              "    Number of dimensions (this is always 2)\n",
              "nnz\n",
              "    Number of stored values, including explicit zeros\n",
              "data\n",
              "    Data array of the matrix\n",
              "indices\n",
              "    CSC format index array\n",
              "indptr\n",
              "    CSC format index pointer array\n",
              "has_sorted_indices\n",
              "    Whether indices are sorted\n",
              "\n",
              "Notes\n",
              "-----\n",
              "\n",
              "Sparse matrices can be used in arithmetic operations: they support\n",
              "addition, subtraction, multiplication, division, and matrix power.\n",
              "\n",
              "Advantages of the CSC format\n",
              "    - efficient arithmetic operations CSC + CSC, CSC * CSC, etc.\n",
              "    - efficient column slicing\n",
              "    - fast matrix vector products (CSR, BSR may be faster)\n",
              "\n",
              "Disadvantages of the CSC format\n",
              "  - slow row slicing operations (consider CSR)\n",
              "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
              "\n",
              "Canonical format\n",
              "  - Within each column, indices are sorted by row.\n",
              "  - There are no duplicate entries.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; from scipy.sparse import csc_array\n",
              "&gt;&gt;&gt; csc_array((3, 4), dtype=np.int8).toarray()\n",
              "array([[0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]], dtype=int8)\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; col = np.array([0, 0, 1, 2, 2, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csc_array((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 4],\n",
              "       [0, 0, 5],\n",
              "       [2, 3, 6]])\n",
              "\n",
              "&gt;&gt;&gt; indptr = np.array([0, 2, 3, 6])\n",
              "&gt;&gt;&gt; indices = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csc_array((data, indices, indptr), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 4],\n",
              "       [0, 0, 5],\n",
              "       [2, 3, 6]])</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 272);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(homo.shape)\n",
        "print(net_upu.shape)\n",
        "print(net_usu.shape)\n",
        "print(net_uvu.shape)\n",
        "print(features.shape)\n",
        "print(label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NplCjBSpxUCg",
        "outputId": "dec4726a-0483-45b5-de75-4ca93909c98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11944, 11944)\n",
            "(11944, 11944)\n",
            "(11944, 11944)\n",
            "(11944, 11944)\n",
            "(11944, 25)\n",
            "(1, 11944)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLC6dT5hxi9k",
        "outputId": "159fb079-0384-4020-adfd-3d92da0467e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t1.0\n",
            "  (1, 0)\t4.0\n",
            "  (2, 0)\t2.0\n",
            "  (3, 0)\t1.0\n",
            "  (4, 0)\t2.0\n",
            "  (5, 0)\t1.0\n",
            "  (6, 0)\t1.0\n",
            "  (7, 0)\t1.0\n",
            "  (8, 0)\t4.0\n",
            "  (9, 0)\t2.0\n",
            "  (0, 1)\t26.0\n",
            "  (1, 1)\t17.0\n",
            "  (2, 1)\t15.0\n",
            "  (3, 1)\t21.0\n",
            "  (4, 1)\t18.0\n",
            "  (5, 1)\t6.0\n",
            "  (6, 1)\t16.0\n",
            "  (7, 1)\t12.0\n",
            "  (8, 1)\t14.0\n",
            "  (9, 1)\t5.0\n",
            "  (8, 2)\t1.0\n",
            "  (1, 3)\t1.0\n",
            "  (1, 4)\t1.0\n",
            "  (6, 4)\t1.0\n",
            "  (2, 5)\t2.0\n",
            "  :\t:\n",
            "  (3, 22)\t1.0\n",
            "  (4, 22)\t1.0\n",
            "  (5, 22)\t1.0\n",
            "  (6, 22)\t1.0\n",
            "  (7, 22)\t1.0\n",
            "  (0, 23)\t13.0\n",
            "  (1, 23)\t45.0\n",
            "  (2, 23)\t24.5\n",
            "  (3, 23)\t14.0\n",
            "  (4, 23)\t18.5\n",
            "  (5, 23)\t22.0\n",
            "  (6, 23)\t16.0\n",
            "  (7, 23)\t39.0\n",
            "  (8, 23)\t17.5\n",
            "  (9, 23)\t16.5\n",
            "  (0, 24)\t1.0\n",
            "  (1, 24)\t1.0\n",
            "  (2, 24)\t1.0\n",
            "  (3, 24)\t1.0\n",
            "  (4, 24)\t1.0\n",
            "  (5, 24)\t1.0\n",
            "  (6, 24)\t1.0\n",
            "  (7, 24)\t1.0\n",
            "  (8, 24)\t1.0\n",
            "  (9, 24)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(homo)"
      ],
      "metadata": {
        "id": "c9sanccX_Xa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52491c5f-011c-4b72-e5da-7acc67b0aa3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (157, 0)\t1.0\n",
            "  (247, 0)\t1.0\n",
            "  (273, 0)\t1.0\n",
            "  (314, 0)\t1.0\n",
            "  (347, 0)\t1.0\n",
            "  (444, 0)\t1.0\n",
            "  (562, 0)\t1.0\n",
            "  (723, 0)\t1.0\n",
            "  (754, 0)\t1.0\n",
            "  (787, 0)\t1.0\n",
            "  (821, 0)\t1.0\n",
            "  (882, 0)\t1.0\n",
            "  (1060, 0)\t1.0\n",
            "  (1097, 0)\t1.0\n",
            "  (1188, 0)\t1.0\n",
            "  (1205, 0)\t1.0\n",
            "  (1208, 0)\t1.0\n",
            "  (1371, 0)\t1.0\n",
            "  (1418, 0)\t1.0\n",
            "  (1419, 0)\t1.0\n",
            "  (1429, 0)\t1.0\n",
            "  (1636, 0)\t1.0\n",
            "  (1651, 0)\t1.0\n",
            "  (1698, 0)\t1.0\n",
            "  (1707, 0)\t1.0\n",
            "  :\t:\n",
            "  (11523, 11943)\t1.0\n",
            "  (11546, 11943)\t1.0\n",
            "  (11566, 11943)\t1.0\n",
            "  (11592, 11943)\t1.0\n",
            "  (11623, 11943)\t1.0\n",
            "  (11698, 11943)\t1.0\n",
            "  (11739, 11943)\t1.0\n",
            "  (11740, 11943)\t1.0\n",
            "  (11765, 11943)\t1.0\n",
            "  (11766, 11943)\t1.0\n",
            "  (11772, 11943)\t1.0\n",
            "  (11774, 11943)\t1.0\n",
            "  (11784, 11943)\t1.0\n",
            "  (11793, 11943)\t1.0\n",
            "  (11796, 11943)\t1.0\n",
            "  (11797, 11943)\t1.0\n",
            "  (11819, 11943)\t1.0\n",
            "  (11829, 11943)\t1.0\n",
            "  (11832, 11943)\t1.0\n",
            "  (11840, 11943)\t1.0\n",
            "  (11858, 11943)\t1.0\n",
            "  (11871, 11943)\t1.0\n",
            "  (11882, 11943)\t1.0\n",
            "  (11941, 11943)\t1.0\n",
            "  (11942, 11943)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# 'homo' 행렬을 밀집 행렬로 변환\n",
        "dense_homo = homo.toarray()\n",
        "\n",
        "# 특정 위치 (0, 1)의 값을 40으로 수정\n",
        "dense_homo[0, 1] = 40\n",
        "dense_homo[1, 0] = 40\n",
        "\n",
        "# 수정된 밀집 행렬을 다시 희소 행렬로 변환\n",
        "modified_homo = csr_matrix(dense_homo)\n",
        "\n",
        "# 수정된 'homo'를 mat_file 딕셔너리에 업데이트\n",
        "mat_file['homo'] = modified_homo"
      ],
      "metadata": {
        "id": "Mj7Tp0IrFTWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat_file['homo'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYWyVbY8GhFE",
        "outputId": "96a37287-0938-441d-db5d-a6ac3ff4a448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t40.0\n",
            "  (0, 157)\t1.0\n",
            "  (0, 247)\t1.0\n",
            "  (0, 273)\t1.0\n",
            "  (0, 314)\t1.0\n",
            "  (0, 347)\t1.0\n",
            "  (0, 444)\t1.0\n",
            "  (0, 562)\t1.0\n",
            "  (0, 723)\t1.0\n",
            "  (0, 754)\t1.0\n",
            "  (0, 787)\t1.0\n",
            "  (0, 821)\t1.0\n",
            "  (0, 882)\t1.0\n",
            "  (0, 1060)\t1.0\n",
            "  (0, 1097)\t1.0\n",
            "  (0, 1188)\t1.0\n",
            "  (0, 1205)\t1.0\n",
            "  (0, 1208)\t1.0\n",
            "  (0, 1371)\t1.0\n",
            "  (0, 1418)\t1.0\n",
            "  (0, 1419)\t1.0\n",
            "  (0, 1429)\t1.0\n",
            "  (0, 1636)\t1.0\n",
            "  (0, 1651)\t1.0\n",
            "  (0, 1698)\t1.0\n",
            "  :\t:\n",
            "  (11943, 11523)\t1.0\n",
            "  (11943, 11546)\t1.0\n",
            "  (11943, 11566)\t1.0\n",
            "  (11943, 11592)\t1.0\n",
            "  (11943, 11623)\t1.0\n",
            "  (11943, 11698)\t1.0\n",
            "  (11943, 11739)\t1.0\n",
            "  (11943, 11740)\t1.0\n",
            "  (11943, 11765)\t1.0\n",
            "  (11943, 11766)\t1.0\n",
            "  (11943, 11772)\t1.0\n",
            "  (11943, 11774)\t1.0\n",
            "  (11943, 11784)\t1.0\n",
            "  (11943, 11793)\t1.0\n",
            "  (11943, 11796)\t1.0\n",
            "  (11943, 11797)\t1.0\n",
            "  (11943, 11819)\t1.0\n",
            "  (11943, 11829)\t1.0\n",
            "  (11943, 11832)\t1.0\n",
            "  (11943, 11840)\t1.0\n",
            "  (11943, 11858)\t1.0\n",
            "  (11943, 11871)\t1.0\n",
            "  (11943, 11882)\t1.0\n",
            "  (11943, 11941)\t1.0\n",
            "  (11943, 11942)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정된 mat_file을 새로운 .mat 파일로 저장\n",
        "new_mat_file_path = '/content/drive/MyDrive/ibk/GNN 공부/FRAUDRE/data/Amazon.mat'\n",
        "io.savemat(new_mat_file_path, mat_file)"
      ],
      "metadata": {
        "id": "splATNVTGHs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일 불러오기\n",
        "mat_file = io.loadmat('data/Amazon.mat')\n",
        "print(mat_file['homo'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY57tSv-S5Iu",
        "outputId": "6dd66f96-a211-4acc-af5f-9d0f90ceae23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (1, 0)\t40.0\n",
            "  (157, 0)\t1.0\n",
            "  (247, 0)\t1.0\n",
            "  (273, 0)\t1.0\n",
            "  (314, 0)\t1.0\n",
            "  (347, 0)\t1.0\n",
            "  (444, 0)\t1.0\n",
            "  (562, 0)\t1.0\n",
            "  (723, 0)\t1.0\n",
            "  (754, 0)\t1.0\n",
            "  (787, 0)\t1.0\n",
            "  (821, 0)\t1.0\n",
            "  (882, 0)\t1.0\n",
            "  (1060, 0)\t1.0\n",
            "  (1097, 0)\t1.0\n",
            "  (1188, 0)\t1.0\n",
            "  (1205, 0)\t1.0\n",
            "  (1208, 0)\t1.0\n",
            "  (1371, 0)\t1.0\n",
            "  (1418, 0)\t1.0\n",
            "  (1419, 0)\t1.0\n",
            "  (1429, 0)\t1.0\n",
            "  (1636, 0)\t1.0\n",
            "  (1651, 0)\t1.0\n",
            "  (1698, 0)\t1.0\n",
            "  :\t:\n",
            "  (11523, 11943)\t1.0\n",
            "  (11546, 11943)\t1.0\n",
            "  (11566, 11943)\t1.0\n",
            "  (11592, 11943)\t1.0\n",
            "  (11623, 11943)\t1.0\n",
            "  (11698, 11943)\t1.0\n",
            "  (11739, 11943)\t1.0\n",
            "  (11740, 11943)\t1.0\n",
            "  (11765, 11943)\t1.0\n",
            "  (11766, 11943)\t1.0\n",
            "  (11772, 11943)\t1.0\n",
            "  (11774, 11943)\t1.0\n",
            "  (11784, 11943)\t1.0\n",
            "  (11793, 11943)\t1.0\n",
            "  (11796, 11943)\t1.0\n",
            "  (11797, 11943)\t1.0\n",
            "  (11819, 11943)\t1.0\n",
            "  (11829, 11943)\t1.0\n",
            "  (11832, 11943)\t1.0\n",
            "  (11840, 11943)\t1.0\n",
            "  (11858, 11943)\t1.0\n",
            "  (11871, 11943)\t1.0\n",
            "  (11882, 11943)\t1.0\n",
            "  (11941, 11943)\t1.0\n",
            "  (11942, 11943)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_net_upu = net_upu.toarray()\n",
        "\n",
        "# 밀집 행렬에서 값 수정 (여기서는 1을 더함)\n",
        "modified_dense_net_upu = dense_net_upu + 1\n",
        "\n",
        "# 수정된 밀집 행렬을 다시 희소 행렬로 변환\n",
        "modified_net_upu = csr_matrix(modified_dense_net_upu)\n",
        "\n",
        "# 수정된 'net_upu'를 mat_file 딕셔너리에 업데이트\n",
        "mat_file['net_upu'] = modified_net_upu"
      ],
      "metadata": {
        "id": "wx6P4XJ7Ha4O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}